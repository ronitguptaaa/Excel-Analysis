{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/23 16:16:03 WARN Utils: Your hostname, Ronits-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.6 instead (on interface en0)\n",
      "24/06/23 16:16:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/23 16:16:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',\n",
    "    password='ronitgupta28',\n",
    "    database='ExcelAnalysis'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee Review Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_columns = \"SHOW COLUMNS FROM EmployeeReview\"\n",
    "cursor.execute(query_columns)\n",
    "columns = [column[0] for column in cursor.fetchall()]\n",
    "\n",
    "query = \"SELECT * FROM EmployeeReview\"\n",
    "cursor.execute(query)\n",
    "data = [row for row in cursor.fetchall()]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "df.createOrReplaceTempView('EmployeeReview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee Survey Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_columns = \"SHOW COLUMNS FROM EmployeeSurvey\"\n",
    "cursor.execute(query_columns)\n",
    "columns = [column[0] for column in cursor.fetchall()]\n",
    "\n",
    "query = \"SELECT * FROM EmployeeSurvey\"\n",
    "cursor.execute(query)\n",
    "data = [row for row in cursor.fetchall()]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "df.createOrReplaceTempView('EmployeeSurvey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH RaceCTE AS (\n",
    "\tSELECT DISTINCT Race FROM EmployeeReview\n",
    "    WHERE Race IS NOT NULL\n",
    ")\n",
    "SELECT Race, ROW_NUMBER() OVER (ORDER BY Race) AS RaceID FROM RaceCTE \"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('RaceMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH GenderCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    CASE \n",
    "\t\tWHEN Gender IN ('F', 'Femail', 'Females', 'Femalr', 'Technically female') THEN 'Female'\n",
    "        WHEN Gender IN ('M', 'male', 'Man') THEN 'Male'\n",
    "\tEND AS Gender\n",
    "        FROM EmployeeReview\n",
    ")\n",
    "SELECT Gender, ROW_NUMBER() OVER (ORDER BY Gender) AS GenderID FROM GenderCTE WHERE Gender IS NOT NULL\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('GenderMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH EducationLevelCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    EducationLevel\n",
    "        FROM EmployeeReview\n",
    "        WHERE EducationLevel IS NOT NULL\n",
    ")\n",
    "SELECT EducationLevel, ROW_NUMBER() OVER (ORDER BY EducationLevel) AS EducationLevelID FROM EducationLevelCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('EducationLevelMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmploymentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH EmploymentTypeCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    EmploymentType\n",
    "        FROM EmployeeReview\n",
    "        WHERE EmploymentType IS NOT NULL\n",
    ")\n",
    "SELECT EmploymentType, ROW_NUMBER() OVER (ORDER BY EmploymentType) AS EmploymentTypeID FROM EmploymentTypeCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('EmploymentTypeMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExperienceLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH ExperienceLevelCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    ExperienceLevel\n",
    "        FROM EmployeeReview\n",
    "        WHERE ExperienceLevel IS NOT NULL\n",
    ")\n",
    "SELECT ExperienceLevel, ROW_NUMBER() OVER (ORDER BY ExperienceLevel) AS ExperienceLevelID FROM ExperienceLevelCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('ExperienceLevelMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH JobTitleCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    JobTitle\n",
    "        FROM EmployeeReview\n",
    "        WHERE JobTitle IS NOT NULL\n",
    ")\n",
    "SELECT JobTitle, ROW_NUMBER() OVER (ORDER BY JobTitle) AS JobTitleID FROM JobTitleCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('JobTitleMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SeniorityLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH SeniorityLevelCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    SeniorityLevel\n",
    "        FROM EmployeeReview\n",
    "        WHERE SeniorityLevel IS NOT NULL\n",
    ")\n",
    "SELECT SeniorityLevel, ROW_NUMBER() OVER (ORDER BY SeniorityLevel) AS SeniorityLevelID FROM SeniorityLevelCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('SeniorityLevelMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH PromotionsCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    Promotions\n",
    "        FROM EmployeeReview\n",
    "        WHERE Promotions IS NOT NULL\n",
    ")\n",
    "SELECT Promotions, ROW_NUMBER() OVER (ORDER BY Promotions) AS PromotionsID FROM PromotionsCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('PromotionsMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IndustryCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    Industry\n",
    "        FROM EmployeeReview\n",
    "        WHERE Industry IS NOT NULL\n",
    ")\n",
    "SELECT Industry, ROW_NUMBER() OVER (ORDER BY Industry) AS IndustryID FROM IndustryCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IndustryMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BusinessType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH BusinessTypeCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    BusinessType\n",
    "        FROM EmployeeReview\n",
    "        WHERE BusinessType IS NOT NULL\n",
    ")\n",
    "SELECT BusinessType, ROW_NUMBER() OVER (ORDER BY BusinessType) AS BusinessTypeID FROM BusinessTypeCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('BusinessTypeMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JobPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH JobPerformanceCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    JobPerformance\n",
    "        FROM EmployeeReview\n",
    "        WHERE JobPerformance IS NOT NULL\n",
    ")\n",
    "SELECT JobPerformance, ROW_NUMBER() OVER (ORDER BY JobPerformance) AS JobPerformanceID FROM JobPerformanceCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('JobPerformanceMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsCompensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IsCompensationCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    IsCompensation\n",
    "        FROM EmployeeReview\n",
    "        WHERE IsCompensation IS NOT NULL\n",
    ")\n",
    "SELECT IsCompensation, ROW_NUMBER() OVER (ORDER BY IsCompensation) AS IsCompensationID FROM IsCompensationCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IsCompensationMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IsGrowthCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    IsGrowth\n",
    "        FROM EmployeeReview\n",
    "        WHERE IsGrowth IS NOT NULL\n",
    ")\n",
    "SELECT IsGrowth, ROW_NUMBER() OVER (ORDER BY IsGrowth) AS IsGrowthID FROM IsGrowthCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IsGrowthMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsDecisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IsDecisionsCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    IsDecisions\n",
    "        FROM EmployeeReview\n",
    "        WHERE IsDecisions IS NOT NULL\n",
    ")\n",
    "SELECT IsDecisions, ROW_NUMBER() OVER (ORDER BY IsDecisions) AS IsDecisionsID FROM IsDecisionsCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IsDecisionsMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsGrowthOpportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IsGrowthOpportunitiesCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    IsGrowthOpportunities\n",
    "        FROM EmployeeReview\n",
    "        WHERE IsGrowthOpportunities IS NOT NULL\n",
    ")\n",
    "SELECT IsGrowthOpportunities, ROW_NUMBER() OVER (ORDER BY IsGrowthOpportunities) AS IsGrowthOpportunitiesID \n",
    "FROM IsGrowthOpportunitiesCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IsGrowthOpportunitiesMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BonusStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH BonusStatusCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    BonusStatus\n",
    "        FROM EmployeeSurvey\n",
    "        WHERE BonusStatus IS NOT NULL\n",
    ")\n",
    "SELECT BonusStatus, ROW_NUMBER() OVER (ORDER BY BonusStatus) AS BonusStatusID FROM BonusStatusCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('BonusStatusMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmployeeCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH EmployeeCountCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    EmployeeCount\n",
    "        FROM EmployeeSurvey\n",
    "        WHERE EmployeeCount IS NOT NULL\n",
    ")\n",
    "SELECT EmployeeCount, ROW_NUMBER() OVER (ORDER BY EmployeeCount) AS EmployeeCountID FROM EmployeeCountCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('EmployeeCountMapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsFairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    \"\"\"WITH IsFairnessCTE AS (\n",
    "\tSELECT DISTINCT  \n",
    "    IsFairness\n",
    "        FROM EmployeeSurvey\n",
    "        WHERE IsFairness IS NOT NULL\n",
    ")\n",
    "SELECT IsFairness, ROW_NUMBER() OVER (ORDER BY IsFairness) AS IsFairnessID FROM IsFairnessCTE\"\"\"\n",
    ")\n",
    "df.createOrReplaceTempView('IsFairnessMapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/23 17:08:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:03 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/23 17:08:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                Race|RaceID|\n",
      "+--------------------+------+\n",
      "|               Asian|     1|\n",
      "|               Asian|     2|\n",
      "|               Asian|     3|\n",
      "|               Asian|     4|\n",
      "|Black or African ...|     5|\n",
      "|Black or African ...|     6|\n",
      "|Black or African ...|     7|\n",
      "|Black or African ...|     8|\n",
      "|Black or African ...|     9|\n",
      "|Black or African ...|    10|\n",
      "|Black or African ...|    11|\n",
      "|Black or African ...|    12|\n",
      "|Black or African ...|    13|\n",
      "|Black or African ...|    14|\n",
      "|Black or African ...|    15|\n",
      "|Black or African ...|    16|\n",
      "|Black or African ...|    17|\n",
      "|Black or African ...|    18|\n",
      "|Black or African ...|    19|\n",
      "|Black or African ...|    20|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.sql(\n",
    "    \"\"\"WITH EmployeeReviewCTE AS (\n",
    "    SELECT DISTINCT\n",
    "        `Respondent ID` AS RespondentID,\n",
    "        to_date(`Start Date`, 'M/d/y H:m') AS StartDate,\n",
    "        Race,\n",
    "        CASE\n",
    "            WHEN Gender IN ('F', 'Femail', 'Females', 'Femalr', 'Technically female') THEN 'Female'\n",
    "            WHEN Gender IN ('M', 'male', 'Man') THEN 'Male'\n",
    "            ELSE Gender\n",
    "        END AS Gender,\n",
    "        CASE\n",
    "            WHEN Age LIKE '%-%' THEN\n",
    "                (CAST(SUBSTRING_INDEX(Age, '-', 1) AS DECIMAL) + CAST(SUBSTRING_INDEX(Age, '-', -1) AS DECIMAL)) / 2\n",
    "            WHEN Age LIKE '%+%' THEN\n",
    "                CAST(SUBSTRING_INDEX(Age, '+', 1) AS DECIMAL)\n",
    "            ELSE\n",
    "                CAST(Age AS DECIMAL)\n",
    "        END AS Age,\n",
    "        EducationLevel,\n",
    "        EmploymentType,\n",
    "        ExperienceLevel,\n",
    "        JobTitle,\n",
    "        SeniorityLevel,\n",
    "        Promotions,\n",
    "        Industry,\n",
    "        BusinessType,\n",
    "        JobPerformance,\n",
    "        IsCompensation,\n",
    "        IsGrowth,\n",
    "        IsDecisions,\n",
    "        IsGrowthOpportunities\n",
    "    FROM\n",
    "        EmployeeReview\n",
    "    WHERE\n",
    "        `Respondent ID` IS NOT NULL\n",
    "        AND `Start Date` IS NOT NULL\n",
    "        AND Race IS NOT NULL\n",
    "        AND Gender IS NOT NULL\n",
    "        AND (Age IS NOT NULL AND Age != '')\n",
    "        AND EducationLevel IS NOT NULL\n",
    "        AND EmploymentType IS NOT NULL\n",
    "        AND ExperienceLevel IS NOT NULL\n",
    "        AND JobTitle IS NOT NULL\n",
    "        AND SeniorityLevel IS NOT NULL\n",
    "        AND Promotions IS NOT NULL\n",
    "        AND Industry IS NOT NULL\n",
    "        AND BusinessType IS NOT NULL\n",
    "        AND JobPerformance IS NOT NULL\n",
    "        AND IsCompensation IS NOT NULL\n",
    "        AND IsGrowth IS NOT NULL\n",
    "        AND IsDecisions IS NOT NULL\n",
    "        AND IsGrowthOpportunities IS NOT NULL\n",
    ")\n",
    "SELECT DISTINCT \n",
    "FROM EmployeeReviewCTE AS ER LEFT JOIN RaceCTE AS RCTE ON LTRIM(RTRIM(LOWER(ER.Race))) = LTRIM(RTRIM(LOWER(RCTE.Race)))\n",
    "        \"\"\"\n",
    ")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
